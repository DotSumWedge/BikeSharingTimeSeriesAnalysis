---
title: "Time_Series_Project"
author: "Sakava Kiv and Derek Rogers"
date: "2024-04-15"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r echo = FALSE}
library(tidyverse)
library(tswge)
library(PolynomF)
library(tidyverse)
library(GGally)
library(astsa)
library(vars)
library(nnfor)
```

# EXPLORE THE DATA

Content
This dataset can be used to forecast demand to avoid oversupply and shortages. It spans from January 1, 2011, until December 31, 2018. Determining new station locations, analyzing movement patterns or planning routes will only be possible with additional data.

date - date with the format yyyy-mm-dd
temp_avg - average daily temperature in degree Celsius
temp_min - minimum daily temperature in degree Celsius
temp_max - maximum daily temperature in degree Celsius
temp_observ - temperature at the time of observation in degree Celsius
precip - amount of precipitation in mm
wind - wind speed in meters per second
wt_fog - weather type fog, ice fog, or freezing fog (may include heavy fog)
wt_heavy_fog - weather type heavy fog or heaving freezing fog (not always distinguished from fog)
wt_thunder - weather type thunder
wt_sleet - weather type ice pellets, sleet, snow pellets, or small hail
wt_hail - weather type hail (may include small hail)
wt_glaze - weather type glaze or rime
wt_haze - weather type smoke or haze
wt_drift_snow - weather type blowing or drifting snow
wt_high_wind - weather type high or damaging winds
wt_mist - weather type mist
wt_drizzle - weather type drizzle
wt_rain - weather type rain (may include freezing rain, drizzle, and freezing drizzle)
wt_freeze_rain - weather type freezing rain
wt_snow - weather type snow, snow pellets, snow grains, or ice crystals
wt_ground_fog - weather type ground fog
wt_ice_fog - weather type ice fog or freezing fog
wt_freeze_drizzle - weather type freezing drizzle
wt_unknown - weather type unknown source of precipitation
casual - number of unregistered customers
registered - number of registered customers
total_cust - sum of registered and casual customers
holiday - indicates whether the day is a holiday or not

Acknowledgements
data used to create this dataset was taken from:

Capital Bikeshare for the bike sharing demand,
NOAA's National Climatic Data Center for weather data,
DC Department of Human Resources for data on public holidays.

The chosen data set is the bike_sharing_dataset.csv from kaggle: https://www.kaggle.com/datasets/juliajemals/bike-sharing-washington-dc

The chosen response (target) variable is total_cust

Being able to model and predict total_cust can help entities directly involved or adjacent to bike sharing better understand and predict the varying demand to avoid oversupply or shortages. Forecasting future demand can help plan bike maintenance as heavily used bikes break down more often. This information can help inform business decisions, setting prices, and creating effective advertisements. 

```{r}
BikeSharing = read.csv("bike_sharing_dataset.csv", header = TRUE)
```

## Data Cleaning

```{r}

head(BikeSharing)
dim(BikeSharing)

# Replace NA with 0 which represents non holidays, 1 represents holidays
BikeSharing$holiday = replace_na(BikeSharing$holiday, 0)
head(BikeSharing$holiday)
str(BikeSharing$holiday)
# Impute the 4 consecutive missing values with the average of the value before and after the missing values

# Calculate the average of the values at positions 1848 and 1853
average_value = mean(c(BikeSharing$total_cust[1848], BikeSharing$total_cust[1853]), na.rm = TRUE)
average_value

length(BikeSharing$total_cust)

# Assign the average value to the missing positions 1849, 1850, 1851, and 1852
BikeSharing$total_cust[1849:1852] = average_value

# Optionally, you can verify the imputation by checking the values at these positions
BikeSharing$total_cust[1848:1853]

# Plot around where the imputed values are
plot(BikeSharing$total_cust[1838:1863], type = "l")

no_missing_values = apply(BikeSharing, 2, function(x) all(complete.cases(x)))
columns_no_missing = names(BikeSharing)[no_missing_values]

# All columns
colnames(BikeSharing)
# Columns with no missing values
print(columns_no_missing)
# date, total_cust, temp_min, temp_max, temp_observ, precip, wind, and holiday

head(BikeSharing)

#check for the indices of the variable we found with no missing values
# Define the vectors
vec1 <- c("date", "temp_avg", "temp_min", "temp_max", "temp_observ", "precip", 
          "wind", "wt_fog", "wt_heavy_fog", "wt_thunder", "wt_sleet", "wt_hail", 
          "wt_glaze", "wt_haze", "wt_drift_snow", "wt_high_wind", "wt_mist", 
          "wt_drizzle", "wt_rain", "wt_freeze_rain", "wt_snow", "wt_ground_fog", 
          "wt_ice_fog", "wt_freeze_drizzle", "wt_unknown", "casual", "registered", 
          "total_cust", "holiday")

vec2 <- c("total_cust", "temp_min", "temp_max", "temp_observ", "precip", "wind", "holiday")

# Get the index of each value in vec2 based on vec1
indices <- match(vec2, vec1)

# Print the indices
print(indices)


#SANITY CHECK FOR INDICES MATCHINGING TO CTS variables with no missing values.
#total_cust = indices 28
#temp_min = indices 3
#temp_max = indices 4
#temp_observ = indices 5
#precip = indices 6
#wind = indices 7
# Pick specific columns using column indexes with no missing values for cts variables

```

### Now we can plot a matrix of scatter plots for the cts variables. We can observe that total_cust or dependent variable has strong correalation with Highly significant (p-value < 0.001) indicated by the three stars with temp_min, temp_max, temp_observ, precip, and wind. From this plot an associated decrease in precip and wind would increase total customers. This is intuititive as people would genrally rent out bikes as the weather has less wind and precipitation.

```{r}
ggpairs(BikeSharing[, c(28,3,4,5,6,7,29)])
```

Plotting the full dataset
The realization plot shows strong periodic trends, wandering behavior, and variance that changes over time. We see slowly dampening autocorrelation with weak and an irregular length periodic behavior. There is a peak at zero in the parzen frequency window (spectral density plot),This could suggest a yearly seasonal trend since we have 1/365 = 0.0027.The parzen window also shows a peak around 0.15, which is suggest a period of 1/7 = 0.1428, This number is close to the .15 estimate we see in the second highest peak from the spectral density plot. Because this data is collected daily, there evidence to suggest a weekly trend. We can hypothesize total_cust could have a greater total_cust on the weekends when all other variables are held constant. Our intuition also suggest ridership is daily, since people will bike continue to bike the next day if that is the main mode of transportation or for exercise purposes.Another thing to note we see evidence of non stationary data as it seems the trend for total_cust increases over time cyclically as and does matter where we are in time series time point.Also note since we see slowly damping sample auto correlations, this suggest the need to difference the data. 

```{r}



# See the Spectral Density Plot up Close
parzen.wge(BikeSharing$total_cust)


acf(BikeSharing$total_cust)

#plot sample of the data 
#we see slowly dampning acf this gives evidence to suggest wandering behavior, also peak at zero for the spectral density adds additional evidence.
plotts.sample.wge(BikeSharing$total_cust)

#step 1 visual test
plot.ts(BikeSharing$total_cust)

head(BikeSharing)

# Assuming BikeSharing$total_cust is a numeric vector with the total customers per time point
# Create a sequence of dates starting from 2011-01-01
dates <- seq(as.Date("2011-01-01"), by="day", length.out=length(BikeSharing$total_cust))

# Combine the dates and total customers into a data frame
BikeSharing_df <- data.frame(Date=dates, Total_Customers=BikeSharing$total_cust)

# Convert the data frame to a ts object
BikeSharing_ts <- ts(BikeSharing_df$Total_Customers, start=c(2011, 1), frequency=365)


# Now plot the time series to see the 5 year period trends
plot.ts(BikeSharing_ts)

#Get Date Range
start_date <- min(BikeSharing$date)
end_date <- max(BikeSharing$date)

# Print the exact date range
print(paste("Start Date:", as.character(start_date)))
print(paste("End Date:", as.character(end_date)))







```

We will try to experiment to estimate for candidate AR or ARMA model based on AIC and BIC values here. We can observe that AN AR(8) model was picked by both AIC AND BIC and also by the PACF function (Box and jenkins method) we saw evidence of an AR(8) as well.

```{r echo = FALSE}
# Top AIC was p = 9, q = 4
aic5.wge(BikeSharing$total_cust, p = 0:12, q = 0:4)
# Top AIC was p = 8, q = 1
aic5.wge(BikeSharing$total_cust, p = 0:9, q = 0:2)
# Top AIC was p = 8, q = 1
aic5.wge(BikeSharing$total_cust, p = 0:9, q = 0:1)
# Top AIC was p = 8, q = 0
aic5.wge(BikeSharing$total_cust, p = 0:9, q = 0:0)
# Top AIC was p = 8, q = 1
aic5.wge(BikeSharing$total_cust, p = 0:8, q = 0:2)
# Top AIC was p = 8, q = 1
aic5.wge(BikeSharing$total_cust, p = 0:8, q = 0:1)
# Top AIC was p = 8, q = 0
aic5.wge(BikeSharing$total_cust, p = 0:8, q = 0:0)


# Top BIC was p = 2, q = 1
aic5.wge(BikeSharing$total_cust, p = 0:12, q = 0:4,type = "bic")
# Top BIC was p = 2, q = 1
aic5.wge(BikeSharing$total_cust, p = 0:9, q = 0:2,type = "bic")
# Top BIC was p = 2, q = 1
aic5.wge(BikeSharing$total_cust, p = 0:9, q = 0:1,type = "bic")
# Top BIC was p = 8, q = 0
aic5.wge(BikeSharing$total_cust, p = 0:9, q = 0:0,type = "bic")
# Top BIC was p = 2, q = 1
aic5.wge(BikeSharing$total_cust, p = 0:8, q = 0:2,type = "bic")
# Top BIC was p = 2, q = 1
aic5.wge(BikeSharing$total_cust, p = 0:2, q = 0:1,type = "bic")
# Top BIC was p = 8, q = 0
aic5.wge(BikeSharing$total_cust, p = 0:8, q = 0:0,type = "bic")

```

### Box and Jenkins Method to identifY AR(p) using PACF function plot

```{r}

pacf(BikeSharing$total_cust) # suggest an AR(8) model

```

Observe that from the code above by running the estimate for p and q for both AIC and BIC for ranges of P and Q of my choosing that make sense, I will probably go with an AR(8) since this seems to strike a balance between the AIC and BIC values. 

And checking with PACF function we see evidence of an AR(8) model. 

Next We will see what happens if I apply a transformation for S=7 and S=365 to see if these are useful.  

I will also check for any (1-B)^d term.

Note to self: 
It is not a good idea to just look at the factor tables. Look at the data, look at the realizations, look at the ACFs, and look at the factor tables, and together you can gather a lot of information to find the most useful model. So before and after differencing. So you should check all these out before and after differences.


```{r}

# transform data
# Difference the data to until we get a stationary model to check for (1-B)^d
# we could use the Dickey-Fuller Test he to see if model as evidence for a unit root, but differencing here I do not see visual evidence for a (1-B) term.
b1=artrans.wge(BikeSharing$total_cust,phi.tr=1)
#b2=artrans.wge(b1,phi.tr=1)
#b3=artrans.wge(b2,phi.tr=1)
#difference the data for (1-B^7) fit
#b7=artrans.wge(b1,phi.tr = c(rep(0,6),1))
#difference the data for (1-B^7) fit
#although the data does not look white we do see in the acf that a sinusoidal trend appears
b7=artrans.wge(BikeSharing$total_cust,phi.tr = c(rep(0,6),1))
```

From the below plots there does not seem to be evidence for a (1-B)^d So we will not include this in the model. 
The Autocorrelation Function (ACF) plot does not suggest white noise. In a white noise series, we would expect most of the spikes in the ACF plot to fall within the confidence interval (usually represented by blue shaded areas or dashed lines), indicating that there is no significant correlation at different lags.

However, the acf indicates that there are significant correlations at various lags. This suggests that the time series data exhibits some patterns or relationships between its values at different times, which is not characteristic of white noise.

```{r}
plotts.sample.wge(b1, arlimits = TRUE)
plotts.sample.wge(b7, arlimits = TRUE)


```

### transform data

```{r}
# transform data
# Difference the data to until we get a stationary model to check for (1-B^S) i.e (1-B^7) and (1-B^365)

#difference the data for (1-B^7) fit
#although the data does not look white we do see in the acf that a sinusoidal trend appears
b7=artrans.wge(BikeSharing$total_cust,phi.tr = c(rep(0,6),1))

#difference the data furthur with (1-B^365) fit
b7_365=artrans.wge(b7,phi.tr = c(rep(0,364),1)) #after doing this the data appears to be more like white noise indicating a stationary model so adding a (1-B^7) and (1-B^365) to our model would be useful.
b7_365_1=artrans.wge(b7_365,phi.tr=1)
# estimate parameters of stationary part
#est.7.365=est.ar.wge(b7_365,p=8)
#est.7.365.1=est.ar.wge(b7_365_1,p=8)
#est.7.365
#est.7.365$res

```

### Estimate the phis for the (1-B^7) differenced data.

```{r}

est.7=est.ar.wge(b7,p=8)

```

### find a P and q for the (1-B^7) differeenced data 

Here we will choose an AR(8) still because of the AIC and BIC balance and Box and Jenkins method. And because AR(8) is a simple model.

```{r echo = FALSE}

# Top AIC was p = 9, q = 0
aic5.wge(b7, p = 0:12, q = 0)
# Top AIC was p = 7, q = 2
aic5.wge(b7, p = 0:9, q = 0:2)
# Top AIC was p = 9, q = 0
aic5.wge(b7, p = 0:9, q = 0:1)
# Top AIC was p = 9, q = 0
aic5.wge(b7, p = 0:9, q = 0:0)
# Top AIC was p = 7, q = 2
aic5.wge(b7, p = 0:8, q = 0:2)
# Top AIC was p = 8, q = 1
aic5.wge(b7, p = 0:8, q = 0:1)
# Top AIC was p = 8, q = 0
aic5.wge(b7, p = 0:8, q = 0:0)


# Top BIC was p = 8, q = 0
aic5.wge(b7, p = 0:12, q = 0,type = "bic")
# Top BIC was p = 8, q = 0
aic5.wge(b7, p = 0:9, q = 0:2,type = "bic")
# Top BIC was p = 8, q = 0
aic5.wge(b7, p = 0:9, q = 0:1,type = "bic")
# Top BIC was p = 8, q = 0
aic5.wge(b7, p = 0:9, q = 0:0,type = "bic")
# Top BIC was p = 8, q = 0
aic5.wge(b7, p = 0:8, q = 0:2,type = "bic")
# Top BIC was p = 1, q = 0
aic5.wge(b7, p = 0:2, q = 0:1,type = "bic")
# Top BIC was p = 8, q = 0
aic5.wge(b7, p = 0:8, q = 0:0,type = "bic")

```

Box and jenkins method for identifiyin AR(P)

```{r}

pacf(BikeSharing$total_cust) # suggest an AR(8) model

```

### we will now estimate the phis using burg method on the difference (1-B^7) Bikeshare data.
AIC and BIC Selects an AR(8), and the final model is:
phi_subs8(B)(1-B^7)X_t = at,
Where phisubs8(B) = 1-0.4043 - 0.0180B^2 - 0.0225B^3- 0.0428B^4 + 0.0060B^5 - 0.0304B^6 + 0.5069B^7 - 0.2151B^8
and Sigmahat_a^2 = 4374309 

```{r}
est.7=est.ar.wge(b7,p=8, method = 'burg')
```

### Check for White noise

```{r}

#step 1 visual test => data seems to be non stationary
plot.ts(est.7$res)


#from this sample plot we can see in the ACF evidence for s=7, since we see peaks at the lags 7,14, and around 21
plotts.sample.wge(est.7$res, arlimits = TRUE)

#difference the data for (1-B^7) fit
#although the data does not look white we do see in the acf that a sinusoidal trend appears
#b7=artrans.wge(BikeSharing$total_cust,phi.tr = c(rep(0,6),1))

# get the phis 
est.7$phi

#run ljung test for white noise, visually we saw that there was evidence against white noise.
ljung.wge(est.7$res,p=8) 

ljung.wge(est.7$res,K=48,p=8)


```

### Forecast 26 weeks (182 days) ahead and one week ahead (7 days) with ASE values

```{r}

#Forecasting with ARUMA model here such that ARUMA(p,d,q) with s=7
f = fore.arima.wge(BikeSharing$total_cust, s=7, phi = est.7$phi, n.ahead = 182, limits =  F, lastn = T, plot=TRUE)

#f

ASE = mean((BikeSharing$total_cust[(length(BikeSharing$total_cust)-181):length(BikeSharing$total_cust)] - f$f)^2)
#ASE 21760890 so this model although it is on the higher end, it has it merits in being simple without
ASE

# Plot the actual vs predicted 'total_cust'
plot(BikeSharing$total_cust, type = "l", main = "Total Customers: Actual vs Predicted 26 weeks", xlab = "Time", ylab = "Total Customers", xlim = c(2800, nrow(BikeSharing)))
lines((nrow(BikeSharing) - 181):nrow(BikeSharing), f$f, col = "red")

#Forecasting with SARIMA model here such that ARIMA(p,d,q) with s=7
f2 = fore.arima.wge(BikeSharing$total_cust, s=7, phi = est.7$phi, n.ahead = 7, limits =  F, lastn = T, plot=TRUE)

#f2

# Plot the actual vs predicted 'total_cust'
plot(BikeSharing$total_cust, type = "l", main = "Total Customers: Actual vs Predicted One Week", xlab = "Time", ylab = "Total Customers", xlim = c(2800, nrow(BikeSharing)))
lines((nrow(BikeSharing) - 6):nrow(BikeSharing), f2$f, col = "red")



ASE = mean((BikeSharing$total_cust[(length(BikeSharing$total_cust)-6):length(BikeSharing$total_cust)] - f2$f)^2)
#ASE 8932177 best performing
ASE

```

### Additional methods to check to see if (1-B^7) term makes sense and is useful
- Overfitting method
- overlaying plots while comparing for Spectral density, ACF, and realizations

```{r}

#compare overfit estimated table with the season factor table of S =7 => observe that when comparing the tables we see some evidence of an S=7, although the estimates are not that #strongly matching the (1-B^7) factor tables
esttable=est.ar.wge(BikeSharing$total_cust,p = 12,method='burg') #overfit for seasonality s= 7
# estimate parameters of stationary part
b7table = factor.wge(c(rep(0,6),1)) #1-B^7 table
#factor.wge(c(rep(0,9),1)) #1-B^10


###################################

#Compare Spectral Densities
sims = 30
SpecDen = parzen.wge(BikeSharing$total_cust, plot = "FALSE")
plot(SpecDen$freq,SpecDen$pzgram, type = "l", lwd = 6)

for( i in 1: sims)
{
   SpecDen2 = parzen.wge(gen.arima.wge(319, s=7, phi = est.7$phi, plot ="FALSE"), plot ="FALSE")
   lines(SpecDen2$freq,SpecDen2$pzgram, lwd = 2, col = "red")
}


#Compare ACFs
sims = 30
ACF = acf(BikeSharing$total_cust, plot = "FALSE")
plot(ACF$lag ,ACF$acf , type = "l", lwd = 6)

for( i in 1: sims)
{
   ACF2 = acf(gen.arima.wge(319, s = 7, phi = est.7$phi, plot ="FALSE"), plot ="FALSE")
   lines(ACF2$lag ,ACF2$acf, lwd = 2, col = "red")
}

#Compare Generated Realizations 
S10AR3gen = gen.arima.wge(319,s = 7,phi = est.7$phi, vara = est.7$avar)

# Set the number of realizations
sims <- 1

# Generate and plot the first realization to establish the plot
S10AR3gen <- gen.arima.wge(319, s = 7, phi = est.7$phi, vara = est.7$avar)
plot(S10AR3gen, type = "l", lwd = 2)

# Generate and plot additional realizations in different colors
for(i in 1:sims) 
{

   S10AR3gen_new <- gen.arima.wge(319, s = 7, phi = est.7$phi, vara = est.7$avar, plot = "FALSE")
   lines(S10AR3gen_new,col = "red", lwd = 2)
}

plotts.sample.wge(S10AR3gen)

```

###  Zoom in the last 182 values to see how the generated realizations fit.

```{r}

# Assuming BikeSharing$total_cust is your time series object
# Select the last 182 values <=> about 26 weeks = 182 days
last_26weeks_values <- tail(BikeSharing$total_cust, 182)

# Now you can use last_60_values in your analysis or plotting
# For example, if you want to plot these values:
plot.ts(last_26weeks_values)

# Set the number of realizations
sims <- 1
# Generate and plot the first realization to establish the plot
S10AR3gen <- gen.arima.wge(319, s = 7, phi = est.7$phi, vara = est.7$avar)
plot(tail(S10AR3gen, 182), type = "l", lwd = 3) # Plot only the last 60 values

# Generate and plot additional realizations in red
for(i in 1:sims) {
   S10AR3gen_new <- gen.arima.wge(319, s = 7, phi = est.7$phi, vara = est.7$avar, plot = "FALSE")
   lines(tail(S10AR3gen_new, 182), col = "red", lwd = 2) # Plot only the last 60 values
}

```

```{r}
# Find ASE for a 26 weeks forecast AR(8) model has an ASE second best so far 10965412
fit_ar = est.ar.wge(BikeSharing$total_cust, p = 8)
preds_arma = fore.arma.wge(BikeSharing$total_cust,
    phi = fit_ar$phi, n.ahead = 182,
    lastn = TRUE, limits = FALSE)

ASE = mean((tail(BikeSharing$total_cust, 182) - preds_arma$f)^2)
ASE #10965412

# Plot the actual vs predicted 'total_cust' for 7 day forcast
plot(BikeSharing$total_cust, type = "l", main = "Total Customers: Actual vs Predicted 26 weeks", xlab = "Time", ylab = "Total Customers", xlim = c(2800, nrow(BikeSharing)))
lines((nrow(BikeSharing) - 181):nrow(BikeSharing), preds_arma$f, col = "red")


###############

# Find ASE for a 1 weeks forecast AR(8) model has an ASE best so far 3095643
fit_ar = est.ar.wge(BikeSharing$total_cust, p = 8)
preds_arma = fore.arma.wge(BikeSharing$total_cust,
    phi = fit_ar$phi, n.ahead = 7,
    lastn = TRUE, limits = FALSE)

ASE = mean((tail(BikeSharing$total_cust, 7) - preds_arma$f)^2)
ASE #3095643

# Plot the actual vs predicted 'total_cust' for 7 day forcast for an AR(8) model
plot(BikeSharing$total_cust, type = "l", main = "Total Customers: Actual vs Predicted one week", xlab = "Time", ylab = "Total Customers", xlim = c(2800, nrow(BikeSharing)))
lines((nrow(BikeSharing) - 6):nrow(BikeSharing), preds_arma$f, col = "red")


################

# ARUMA (8,0,0) S = 7 for 26 weeks
f26w = fore.arima.wge(BikeSharing$total_cust, s=7, phi = est.7$phi, n.ahead = 182, limits =  F, lastn = T, plot=TRUE)
#ASE = mean((BikeSharing$total_cust[(length(BikeSharing$total_cust)-181):length(BikeSharing$total_cust)] - f6m$f)^2)
#ASE

#More concise way to calculate ASE
ASE = mean((tail(BikeSharing$total_cust, 182) - f26w$f)^2)
ASE #21760890

# Plot the actual vs predicted 'total_cust' for 7 day forcast for an AR(8) model
plot(BikeSharing$total_cust, type = "l", main = "Total Customers: Actual vs Predicted one week", xlab = "Time", ylab = "Total Customers", xlim = c(2800, nrow(BikeSharing)))
lines((nrow(BikeSharing) - 181):nrow(BikeSharing), f26w$f, col = "red")

###########

# ARUMA (8,0,0) S = 7 for 1 week forecast
f1w = fore.arima.wge(BikeSharing$total_cust, s=7, phi = est.7$phi, n.ahead = 7, limits =  F, lastn = T, plot=TRUE)
#ASE = mean((BikeSharing$total_cust[(length(BikeSharing$total_cust)-181):length(BikeSharing$total_cust)] - f6m$f)^2)
#ASE

#More concise way to calculate ASE
ASE = mean((tail(BikeSharing$total_cust, 7) - f1w$f)^2)
ASE #8932177

# Plot the actual vs predicted 'total_cust' for 7 day forcast for an AR(8) model
plot(BikeSharing$total_cust, type = "l", main = "Total Customers: Actual vs Predicted one week", xlab = "Time", ylab = "Total Customers", xlim = c(2800, nrow(BikeSharing)))
lines((nrow(BikeSharing) - 6):nrow(BikeSharing), f1w$f, col = "red")


```
## FINAL MODEL ARUMA(8,0,0) S=7
## (1 - 0.4043B - 0.01801B^2 - 0.0225B^3 - 0.0428B^4 + 0.0060B^5 - 0.0304B^6 + 0.5069B^7 - 0.2151B^8)(1 - B^7)X_t = a_t

### Rolling Window for 1 week for FINAL MODEL ARUMA(8,0,0) S=7 => "The Rolling Window RMSE is:  1973.381"
## Note ROLLING WINDOW RMSE we cannot get for Multivariate processes, So I only got the rolling window RMSE for the simpler Univariate models.

```{r echo = FALSE}

est.7$phi #gives estimated phis to plug in.
roll.win.rmse.wge(BikeSharing$total_cust,phi = c(0.40432768,  0.01801666,  0.02246405,  0.04287993, -0.00599795,  0.03044390, -0.50685544,  0.21513204), s = 7, horizon = 7)

```

### Rolling Window for 26 week for FINAL MODEL ARUMA(8,0,0) S=7 => "The Rolling Window RMSE is:  2274.046"


```{r echo = FALSE}

roll.win.rmse.wge(BikeSharing$total_cust,phi = c(0.40432768,  0.01801666,  0.02246405,  0.04287993, -0.00599795,  0.03044390, -0.50685544,  0.21513204), s = 7, horizon = 26)

```

### Rolling Window for 26 week for MODEL AR(8) => "The Rolling Window RMSE is:  3712.421"


```{r echo = FALSE}

roll.win.rmse.wge(BikeSharing$total_cust,phi = c(0.40432768,  0.01801666,  0.02246405,  0.04287993, -0.00599795,  0.03044390, -0.50685544,  0.21513204),  horizon = 26)

```

### Rolling Window for 1 week for MODEL AR(8) => "The Rolling Window RMSE is:  4229.392"

```{r echo = FALSE}

roll.win.rmse.wge(BikeSharing$total_cust,phi = c(0.40432768,  0.01801666,  0.02246405,  0.04287993, -0.00599795,  0.03044390, -0.50685544,  0.21513204), horizon = 7)

```


### Checking for missing values (MCAR)

```{r echo = FALSE}

library(vars)


#Delete all if missing completely at random
#First we need to check for missing values
dim(BikeSharing)
sum(is.na(BikeSharing))
str(BikeSharing)
#2516 missing values int eh wt_rain column.
#sum(is.na(BikeSharing$wt_rain))
#Example of MCAR idea: The probability of missing does not depend on the data, the covariates.  It is as if the wind blew away records at random and wt_rain all equally likely to by blown away (missing).  List wise Deletion OK and Imputation OK!
#now we need to determine if the values are missing completely at random, so lets check this by plotting the data visually with a scatter plot


#We can observe from this scatter plot that the wt_rain values that are missing for the beers are spread out over the many present ones in this data set. This suggests that the data is missing completely at random so we do not need to include those wt_rain.

library(ggplot2)
library(plotly)

data <- data.frame(x = is.na(BikeSharing$wt_rain))


gg <- ggplot(data, aes(x = 1:nrow(data), y = x)) +
  geom_point(size = 1, height = .5, width = .5, color = "red") +
  xlab("days by row number") +
 ylab("wt_rain Values Present or Missing") +
 labs(title = "Scatter Plot of Missing wt_rain Values", size = 10) +
 scale_y_discrete(labels = c("Present", "Missing")) +
 scale_x_continuous(breaks = seq(0, nrow(data), by = 100)) +
 theme(axis.text.x = element_text(angle = 90, hjust  = 1)) + 
 theme_classic()
gg

```

## VARS MODEL has higer ASE values due to the model expecting stationary processes, but our data process is non-stationary.

```{r}


BSsmall = BikeSharing[1:2740,] 

#Easier to read
TotalCust = BSsmall$total_cust
Precipitation = BSsmall$precip
Wind = BSsmall$wind
Tempe_Observe = BSsmall$temp_observ
Temp_Min = BSsmall$temp_min
Temp_Max = BSsmall$temp_max


#head(BSsmall)


################################

#run the code below with function VARselect to find a p = 9 to fit into Var Function

VAR_Bikeshare2 = VARselect(cbind(TotalCust,Precipitation,Wind,Tempe_Observe,Temp_Min,Temp_Max),lag.max = 10, type = "both")
VAR_Bikeshare2

# VARS MODEl Without Seasonality forecast 26 weeks ahead
VAR_Bikeshare3 = VAR(cbind(TotalCust,Precipitation,Wind,Tempe_Observe,Temp_Min,Temp_Max),lag.max = 10, type = "both",p = 9)

VAR_Bikeshare3

#make predictions with model with 182 prediction (26 weeks)
preds=predict(VAR_Bikeshare3,n.ahead=182)

preds

#Plot
plot(BikeSharing$total_cust, type = "l",xlim = c(2500,2922), ylab = "Total Customers", main = "6 month Total Customer Forecast")
lines(seq(2741,2922,1), preds$fcst$TotalCust[,1], type = "l", col = "red")


#Actual 182 sum(TotalCust -predicted)^2/182
ASE = mean((BikeSharing$total_cust[2741:2922] - preds$fcst$TotalCust[,1][1:182])^2)
ASE #19510219

#############################

#run the code below with function VARselect to find a p = 9 to fit into Var Function

VAR_Bikeshare2 = VARselect(cbind(TotalCust,Precipitation,Wind,Tempe_Observe,Temp_Min,Temp_Max),lag.max = 10, type = "both")
VAR_Bikeshare2

# VARS MODEl Without Seasonality forecast 7 weeks ahead
VAR_Bikeshare3 = VAR(cbind(TotalCust,Precipitation,Wind,Tempe_Observe,Temp_Min,Temp_Max),lag.max = 10, type = "both",p = 9)

VAR_Bikeshare3

#make predictions with model with 182 prediction (26 weeks)
preds=predict(VAR_Bikeshare3,n.ahead=7)

preds

#Plot
plot(BikeSharing$total_cust, type = "l",xlim = c(2500,2922), ylab = "Total Customers", main = "1 Week Total Customer Forecast")
lines(seq(2916,2922,1), preds$fcst$TotalCust[,1], type = "l", col = "red")


#Actual 7 sum(TotalCust -predicted)^2/182
ASE = mean((BikeSharing$total_cust[2916:2922] - preds$fcst$TotalCust[,1][1:7])^2)
ASE #79846728

#############################

### Forecast Ahead 26 weeks seasonality = 182

#chooses p =9 
VARselect(cbind(TotalCust,Precipitation,Wind,Tempe_Observe,Temp_Min,Temp_Max),lag.max = 10, season = 182, type = "both")
#TotalCust data with 2740

# VARS MODEl With Seasonality forecast 26 weeks ahead
TotalCustVAR = VAR(cbind(TotalCust,Precipitation,Wind,Tempe_Observe,Temp_Min,Temp_Max),season = 182, type = "both",p = 9)
preds=predict(TotalCustVAR,n.ahead=182)

#Plot to show Forcast prediction up to 26 weeks
#plot(seq(1,2922,1), BikeSharing$total_cust, type = "l",xlim = c(2500,3104), ylab = "Total Customers", main = "26 weeks Total Customer Forecast")
#lines(seq(2923,3104,1), preds$fcst$TotalCust[,1], type = "l", col = "red")

#Plot to show Forcast prediction up to 26 Weeks
plot(seq(1,2922,1), BikeSharing$total_cust, type = "l",xlim = c(2500,3104), ylab = "Total Customers", main = "26 weeks Total Customer Forecast")
lines(seq(2741,2922,1), preds$fcst$TotalCust[,1], type = "l", col = "red")

#Actual 182 sum(TotalCust -predicted)^2/182
ASE = mean((BikeSharing$total_cust[2741:2922] - preds$fcst$TotalCust[,1][1:182])^2)
ASE #20014036

###############################


### Forecast Ahead 1 week seasonality = 7

#chooses p =9 
VARselect(cbind(TotalCust,Precipitation,Wind,Tempe_Observe,Temp_Min,Temp_Max),lag.max = 10, season = 7, type = "both")
#TotalCust data with 2740

# VARS MODEl With Seasonality forecast 26 weeks ahead
TotalCustVAR = VAR(cbind(TotalCust,Precipitation,Wind,Tempe_Observe,Temp_Min,Temp_Max),season = 7, type = "both",p = 9)
preds=predict(TotalCustVAR,n.ahead=7)

#Plot to show Forcast prediction up to 26 weeks
#plot(seq(1,2922,1), BikeSharing$total_cust, type = "l",xlim = c(2500,3104), ylab = "Total Customers", main = "1 Week Total Customer Forecast")
#lines(seq(2923,3104,1), preds$fcst$TotalCust[,1], type = "l", col = "red")

#Plot to show Forcast prediction up to 26 Weeks
plot(seq(1,2922,1), BikeSharing$total_cust, type = "l",xlim = c(2500,3104), ylab = "Total Customers", main = "1 Week Total Customer Forecast")
lines(seq(2916,2922,1), preds$fcst$TotalCust[,1], type = "l", col = "red")

#Actual 7 sum(TotalCust -predicted)^2/182
ASE = mean((BikeSharing$total_cust[2916:2922] - preds$fcst$TotalCust[,1][1:7])^2)
ASE #80771087


###############################


```
## MLP Neural Network model

Note for this MLP it took too much computational time so I trained on 877 observations and only using 1059 data points and not all of the original 2922.

```{r}

BSsmall = BikeSharing[1:877,] #877 is about 30% of 2922
length(BSsmall$precip)



#Easier to read
TotalCust = BSsmall$total_cust
Precipitation = BSsmall$precip
Wind = BSsmall$wind
Temp_Observe = BSsmall$temp_observ
Temp_Min = BSsmall$temp_min
Temp_Max = BSsmall$temp_max

str(BikeSharing)

# Get the minimum and maximum values of the precip column
min_valueprecip <- min(BikeSharing$precip)
max_valueprecip <- max(BikeSharing$precip)

# Print the minimum and maximum values
#use this values to see what you should set for the ylim for plots.
print(min_valueprecip)
print(max_valueprecip)

# Get the minimum and maximum values of the wind column
min_valuewind <- min(BikeSharing$wind)
max_valuewind <- max(BikeSharing$wind)

# Print the minimum and maximum values
#use this values to see what you should set for the ylim for plots.
print(min_valuewind)
print(max_valuewind)

# Get the minimum and maximum values of the tempobserved column
min_valuetempobserved <- min(BikeSharing$temp_observ)
max_valuetempobserved <- max(BikeSharing$temp_observ)

# Print the minimum and maximum values
#use this values to see what you should set for the ylim for plots.
print(min_valuetempobserved)
print(max_valuetempobserved)

# Get the minimum and maximum values of the tempmin column
min_valuetempmin <- min(BikeSharing$temp_min)
max_valuetempmin <- max(BikeSharing$temp_min)

# Print the minimum and maximum values
#use this values to see what you should set for the ylim for plots.
print(min_valuetempmin)
print(max_valuetempmin)

# Get the minimum and maximum values of the tempmax column
min_valuetempmax <- min(BikeSharing$temp_max)
max_valuetempmax <- max(BikeSharing$temp_max)

# Print the minimum and maximum values
#use this values to see what you should set for the ylim for plots.
print(min_valuetempmax)
print(max_valuetempmax)


#forecast Precipitation, Wind, Temp_observed, Temp_Min, Temp_Max

length(Precipitation)

#Precipitation
fit.mlp.precipitation = mlp(ts(BSsmall$precip), reps = 10, comb = "median")
plot(fit.mlp.precipitation)
fore.mlp.precipitation = forecast(fit.mlp.precipitation, h = 182)
plot(fore.mlp.precipitation, ylim = c(0,120), main = "Precipitation (mililmeters) MLP Forecasts")


#Wind
fit.mlp.wind = mlp(ts(BSsmall$wind), reps = 10, comb = "median")
plot(fit.mlp.wind)
fore.mlp.wind = forecast(fit.mlp.wind, h = 182)
plot(fore.mlp.wind, ylim = c(0,13), main = "Wind Speed in meters per second MLP Forecasts")


#Temp_Observe
fit.mlp.temp_observe = mlp(ts(BSsmall$temp_observ), reps = 10, comb = "median")
plot(fit.mlp.temp_observe)
fore.mlp.temp_observe = forecast(fit.mlp.temp_observe, h = 182)
plot(fore.mlp.temp_observe, ylim = c(-16,29), main = "Temperature Observed in degree Celsius MLP Forecasts")

#Temp_Min
fit.mlp.temp_min = mlp(ts(BSsmall$temp_min), reps = 10, comb = "median")
plot(fit.mlp.temp_min)
fore.mlp.temp_min = forecast(fit.mlp.temp_min, h = 182)
plot(fore.mlp.temp_min, ylim = c(-17,27), main = "Minimum Daily Temperature in degree Celsius MLP Forecasts")

#Temp_Max
fit.mlp.temp_max = mlp(ts(BSsmall$temp_max), reps = 10, comb = "median")
plot(fit.mlp.temp_max)
fore.mlp.temp_max = forecast(fit.mlp.temp_max, h = 182)
plot(fore.mlp.temp_max, ylim = c(-8,38), main = "Maximum Daily Temperature in degree Celsius MLP Forecasts")

#Package the above predictor variables into a dataframe
BSsmallDF_fore = data.frame(Days = ts(seq(1,1059,1)),precip= ts(c(BSsmall$precip, fore.mlp.precipitation$mean)),wind= ts(c(BSsmall$wind,fore.mlp.wind$mean)),temp_oberv = ts(c(BSsmall$temp_observ,fore.mlp.temp_observe$mean)),temp_min = ts(c(BSsmall$temp_min,fore.mlp.temp_min$mean)), temp_max = ts(c(BSsmall$temp_max,fore.mlp.temp_max$mean)))
BSsmallDF_fore # These are the forecasted explantory variables


#forecast total_cust using mlp forecasted xreg (don't need to forecast days)
#fit MLP(training) (get the most optimal weights for what we know)
#all 1-877 that we know
BSsmallDF = data.frame(Days = ts(seq(1,877,1)), precip= ts(BSsmall$precip),wind= ts(BSsmall$wind),temp_oberv= ts(BSsmall$temp_observ),temp_min = ts(BSsmall$temp_min), temp_max= ts(BSsmall$temp_max))
fit.mlp = mlp(ts(BSsmall$total_cust),reps = 10, comb = "median",xreg=BSsmallDF)
fit.mlp
plot(fit.mlp)


#MLP forecast 1 Week
fore.mlp = forecast(fit.mlp, h=7, xreg = BSsmallDF_fore)
plot(fore.mlp)
ASE = mean((BikeSharing$total_cust[1053:1059] - fore.mlp$mean)^2)
ASE #5111357


#plot
plot(seq(1,1059,1),BikeSharing$total_cust[1:1059], type = 'l',xlim = c(800,1070), ylab = "Total Customers", main = "1 Week Total Customer Forecast")
lines(seq(1053,1059,1), fore.mlp$mean, type = "l", col ="red")

#MLP forecast 26 Weeks
fore.mlp = forecast(fit.mlp, h=182, xreg = BSsmallDF_fore)
plot(fore.mlp)
ASE = mean((BikeSharing$total_cust[878:1059] - fore.mlp$mean)^2)
ASE #2859746


#plot
plot(seq(1,1059,1),BikeSharing$total_cust[1:1059], type = 'l',xlim = c(800,1070), ylab = "Total Customers", main = "6 month Total Customer Forecast")
lines(seq(878,1059,1), fore.mlp$mean, type = "l", col ="red")





```
Ensemble model for forcast of 1 week
```{r}

#ensemble of ARUMA(8,0,0) S = 7 with

#ensemble = (preds$fcst$TotalCust[,1] + fore.mlp$mean)/2

ensemble = (f1w$f + fore.mlp$mean)/2
#plot
plot(seq(1,1059,1),BikeSharing$total_cust[1:1059], type = 'l',xlim = c(800,1070), ylab = "Total Customers", main = "26 Week Total Customer Forecast")
lines(seq(878,1059,1), ensemble, type = "l", col ="green")

ASE = mean((BikeSharing$total_cust[878:1059] - ensemble)^2,na.rm = TRUE)
ASE #6137926

```


